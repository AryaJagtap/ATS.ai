# ðŸŽ¯ ATS.ai â€” AI-Powered Recruitment Platform

A **production-grade, AI-powered Applicant Tracking System** that scores candidate resumes against job descriptions using LLM analysis (OpenAI GPT-4o-mini â†’ Gemini 2.5 Flash â†’ Keyword Fallback). Features real-time streaming progress, multi-JD matching, concurrent batch processing, and one-click Excel report export.

---

## âœ¨ Features

| Feature | Description |
|---------|-------------|
| ðŸ¤– **Multi-LLM Cascade** | GPT-4o-mini (primary) â†’ Gemini 2.5 Flash (fallback) â†’ TF-IDF keyword matching (offline) |
| ðŸ“Š **ATS Scoring (0-100)** | Weighted blend of LLM semantic analysis (70%) + keyword matching (30%) |
| ðŸ“‹ **Multi-JD Matching** | Upload multiple job descriptions â€” candidates are scored against each and matched to the best-fit role |
| âš¡ **High-Performance** | 120 resumes analyzed in ~6 minutes with batch concurrency (15 parallel) and retry logic |
| ðŸ”„ **Real-time Streaming** | Live progress via Server-Sent Events with elapsed time counter |
| ðŸŒ™â˜€ï¸ **Dark / Light Theme** | Toggle between themes with smooth transitions |
| ðŸ“ **Drag & Drop Upload** | Upload CSV/XLSX candidate files or select multiple PDF/DOCX resumes directly |
| ðŸ“‹ **JD Input** | Paste job description text or upload PDF/DOCX/TXT files |
| ðŸ“¸ **Photo Link Extraction** | Auto-detects "Photograph" column from spreadsheet and includes in results |
| ðŸ“¥ **Excel Export** | One-click download of styled, color-coded Excel report |
| ðŸ” **API Key Config** | Enter API keys in the UI or use environment variables |
| ðŸ“± **Responsive** | Works on desktop, tablet, and mobile |

---

## ðŸ—ï¸ Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Next.js Frontend  â”‚  HTTP   â”‚   FastAPI Backend         â”‚
â”‚   (Vercel)          â”‚ â”€â”€â”€â”€â”€â”€> â”‚   (Render)                â”‚
â”‚                     â”‚   SSE   â”‚                           â”‚
â”‚  â€¢ React UI         â”‚ <â”€â”€â”€â”€â”€â”€ â”‚  â€¢ utils/scorer.py        â”‚
â”‚  â€¢ Dark/Light Theme â”‚         â”‚  â€¢ utils/downloader.py    â”‚
â”‚  â€¢ Drag & Drop      â”‚         â”‚  â€¢ utils/extractor.py     â”‚
â”‚  â€¢ Live Progress    â”‚         â”‚  â€¢ utils/export.py        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## âš¡ Performance Benchmarks

| Metric | Value |
|--------|-------|
| **Per-resume analysis** | ~2-3 seconds |
| **120 resumes batch** | ~6 minutes |
| **Batch concurrency** | 15 resumes in parallel |
| **PDF extraction** | PyMuPDF (primary, ~10x faster than pdfplumber) |
| **LLM model** | gpt-4o-mini (2-3x faster than gpt-4o, same quality for structured JSON) |
| **Rate limit handling** | Auto-retry with exponential backoff (up to 2 retries per provider) |
| **Keyword + LLM scoring** | Runs in parallel via ThreadPoolExecutor |

---

## ðŸ“ Project Structure

```
ATS-Latest/
â”œâ”€â”€ frontend/                  # Next.js React app
â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”œâ”€â”€ app/
â”‚   â”‚   â”‚   â”œâ”€â”€ page.js        # Main dashboard
â”‚   â”‚   â”‚   â”œâ”€â”€ layout.js      # Root layout + SEO
â”‚   â”‚   â”‚   â”œâ”€â”€ globals.css    # Design system (dark/light)
â”‚   â”‚   â”‚   â””â”€â”€ icon.png       # Favicon
â”‚   â”‚   â””â”€â”€ components/
â”‚   â”‚       â”œâ”€â”€ Header.js      # Brand + theme toggle
â”‚   â”‚       â”œâ”€â”€ FileUpload.js  # Drag & drop upload
â”‚   â”‚       â”œâ”€â”€ JobDescription.js  # JD paste/upload (multi-file)
â”‚   â”‚       â”œâ”€â”€ MetricsCards.js    # Score summary
â”‚   â”‚       â”œâ”€â”€ ProgressTracker.js # Live progress bar
â”‚   â”‚       â””â”€â”€ ResultsTable.js    # Sortable results + matched role
â”‚   â”œâ”€â”€ .env.local             # Frontend env vars
â”‚   â”œâ”€â”€ vercel.json            # Vercel deploy config
â”‚   â””â”€â”€ package.json
â”œâ”€â”€ backend/                   # FastAPI Python app
â”‚   â”œâ”€â”€ main.py                # REST API endpoints + batch processing
â”‚   â”œâ”€â”€ config.py              # API key loader
â”‚   â”œâ”€â”€ requirements.txt       # Python dependencies (pinned)
â”‚   â”œâ”€â”€ Dockerfile             # Container for Render
â”‚   â”œâ”€â”€ .env.example           # Env template
â”‚   â””â”€â”€ utils/
â”‚       â”œâ”€â”€ scorer.py          # LLM + keyword scoring (parallel, retry)
â”‚       â”œâ”€â”€ downloader.py      # Resume download (GDrive, Dropbox, etc.)
â”‚       â”œâ”€â”€ extractor.py       # PDF (PyMuPDF) / DOCX / TXT extraction
â”‚       â””â”€â”€ export.py          # Styled Excel generation
â”œâ”€â”€ render.yaml                # Render blueprint
â”œâ”€â”€ .gitignore
â””â”€â”€ README.md
```

---

## ðŸš€ Local Setup Guide

### Prerequisites

- **Python 3.10+** â€” [Download](https://www.python.org/downloads/)
- **Node.js 18+** â€” [Download](https://nodejs.org/)
- **Git** â€” [Download](https://git-scm.com/)
- **API Keys** (at least one):
  - [OpenAI API Key](https://platform.openai.com/api-keys) (recommended, uses GPT-4o-mini)
  - [Google Gemini API Key](https://aistudio.google.com/apikey) (free fallback)

---

### Step 1: Clone the Repository

```bash
git clone https://github.com/YOUR_USERNAME/ATS-Latest.git
cd ATS-Latest
```

---

### Step 2: Set Up the Backend (Python)

```bash
cd backend

# Create and activate virtual environment
python -m venv venv

# Windows:
venv\Scripts\activate
# macOS/Linux:
# source venv/bin/activate

# Install dependencies
pip install -r requirements.txt
```

---

### Step 3: Configure Backend Environment Variables

```bash
# Copy the template
copy .env.example .env     # Windows
# cp .env.example .env     # macOS/Linux
```

Edit `backend/.env`:
```env
OPENAI_API_KEY=sk-proj-your-key-here
GEMINI_API_KEY=AIzaSy-your-key-here
ALLOWED_ORIGINS=http://localhost:3000
```

---

### Step 4: Start the Backend Server

```bash
uvicorn main:app --reload --port 8000
```

Verify: Open `http://localhost:8000/api/health`

---

### Step 5: Set Up the Frontend (Node.js)

Open a **new terminal** (keep the backend running):

```bash
cd frontend
npm install
```

---

### Step 6: Configure Frontend Environment

`frontend/.env.local` should contain:
```env
NEXT_PUBLIC_API_URL=http://localhost:8000
```

---

### Step 7: Start the Frontend

```bash
npm run dev
```

Open **http://localhost:3000** in your browser.

---

### Step 8: Use the Platform

1. (Optional) Click **âš™ï¸ Settings** to enter API keys if not using `.env`
2. **Upload** a CSV/XLSX file with candidate data, or select multiple PDF resumes
3. **Enter/Upload** one or more Job Descriptions
4. Click **ðŸš€ Start Analysis** and watch real-time progress
5. Review results in the interactive table (click â–¶ to expand details)
6. Click **ðŸ“¥ Download Excel Report** for the styled report

---

## ðŸŒ Deployment Guide (Production)

### Step 9: Push to GitHub

```bash
cd ATS-Latest
git init
git add .
git commit -m "ATS.ai v2.0 â€” Production release"
git branch -M main
git remote add origin https://github.com/YOUR_USERNAME/ATS-Latest.git
git push -u origin main
```

---

### Step 10: Deploy Backend on Render

1. Go to [render.com](https://render.com) â†’ **New +** â†’ **Web Service**
2. Connect your **GitHub repository**
3. Configure:
   - **Name**: `ats-backend`
   - **Root Directory**: `backend`
   - **Runtime**: `Docker`
   - **Instance Type**: Free (or Starter for better performance)
4. Add **Environment Variables**:
   - `OPENAI_API_KEY` = your OpenAI key
   - `GEMINI_API_KEY` = your Gemini key
   - `ALLOWED_ORIGINS` = `https://your-app.vercel.app` (update after Step 11)
5. Click **Create Web Service** â†’ wait ~3-5 minutes
6. Copy your backend URL (e.g., `https://ats-backend-xxxx.onrender.com`)

---

### Step 11: Deploy Frontend on Vercel

1. Go to [vercel.com](https://vercel.com) â†’ **Add New** â†’ **Project**
2. **Import** your GitHub repository
3. Configure:
   - **Framework Preset**: Next.js (auto-detected)
   - **Root Directory**: `frontend`
4. Add **Environment Variable**:
   - `NEXT_PUBLIC_API_URL` = `https://ats-backend-xxxx.onrender.com` (your Render URL)
5. Click **Deploy** â†’ wait ~1-2 minutes

---

### Step 12: Update Render CORS

Go to Render dashboard â†’ ats-backend â†’ Environment â†’ Update:
- `ALLOWED_ORIGINS` = `https://your-app.vercel.app`

Redeploy the backend.

---

### Step 13: Done! ðŸŽ‰

Your ATS platform is now live:
- **Frontend**: `https://your-app.vercel.app`
- **Backend**: `https://ats-backend-xxxx.onrender.com`

> **Note**: Render free tier services spin down after 15 minutes of inactivity. The first request after idle may take ~30 seconds to cold start. For production use, consider Render's Starter plan ($7/month) to avoid cold starts.

---

## ðŸ“„ Input File Format

### CSV/XLSX Upload

Your spreadsheet must contain at minimum:

| Column | Description |
|--------|-------------|
| `Name` (or any column with "name") | Candidate name |
| `Resume URL` / `Resume Link` / any column with "url", "resume", or "link" | Direct link to resume (Google Drive, Dropbox, direct URL) |
| `Photograph` / `Photo` / `Image` (optional) | Link to candidate photo â€” auto-detected and included in results |

### Direct Upload

You can also select **multiple PDF/DOCX resumes** directly without a spreadsheet.

### Example CSV:
```csv
Name,Email,Resume Link,Photograph
John Doe,john@email.com,https://drive.google.com/file/d/xxx/view,https://drive.google.com/open?id=yyy
Jane Smith,jane@email.com,https://example.com/resume.pdf,
```

---

## ðŸ“Š Output Report

The exported Excel report includes:

| Column | Description |
|--------|-------------|
| Serial Number | Rank by score |
| Candidate Name | From input file or extracted by LLM |
| Phone Number | Extracted from resume |
| Email | Extracted from resume |
| Status | Engine used (GPT / Gemini / Keyword / Failed) |
| ATS Score | 0-100 weighted score |
| Resume Summary | AI-generated summary |
| Missing Requirements | Gaps vs. JD requirements |
| Job Description Summary | Key JD requirements |
| Target Job Role | Role from JD |
| Best Fit Role | Ideal role for candidate |
| Matched Role | Best-matched JD (when using multi-JD) |
| Resume Link | Original URL |
| Photo Link | From spreadsheet or resume |
| Recommendation | Yes / No / Maybe |

Scores are color-coded: ðŸŸ¢ â‰¥70 | ðŸŸ¡ â‰¥50 | ðŸ”´ <50

---

## ðŸ”§ Environment Variables

### Backend (`backend/.env`)

| Variable | Required | Description |
|----------|----------|-------------|
| `OPENAI_API_KEY` | Optional* | OpenAI API key for GPT-4o-mini scoring |
| `GEMINI_API_KEY` | Optional* | Google Gemini API key for fallback |
| `ALLOWED_ORIGINS` | Yes | Comma-separated allowed frontend URLs |

*At least one LLM key recommended. Without both, scoring uses keyword matching only.

### Frontend (`frontend/.env.local`)

| Variable | Required | Description |
|----------|----------|-------------|
| `NEXT_PUBLIC_API_URL` | Yes | Backend API URL |

---

## ðŸ›¡ï¸ How Scoring Works

```
1. Download/extract resume text
   â”œâ”€â”€ PyMuPDF (primary â€” fastest PDF parser)
   â””â”€â”€ PyPDF2 (fallback) / python-docx for DOCX
2. Score with LLM cascade (keyword + LLM run in parallel):
   â”œâ”€â”€ Try OpenAI GPT-4o-mini (primary, with retry on rate limit)
   â”œâ”€â”€ Try Gemini 2.5 Flash (fallback, with retry on rate limit)
   â””â”€â”€ Keyword + TF-IDF (offline fallback)
3. Final Score = (LLM Score Ã— 0.7) + (Keyword Score Ã— 0.3)
4. If multi-JD: score against each JD, select best match
```

---

## ðŸ”— Tech Stack

| Layer | Technology |
|-------|-----------|
| **Frontend** | Next.js 15, React 19, CSS Variables |
| **Backend** | FastAPI, Python 3.10+ |
| **LLM** | OpenAI GPT-4o-mini, Google Gemini 2.5 Flash |
| **PDF Parsing** | PyMuPDF (primary), PyPDF2 (fallback) |
| **NLP** | scikit-learn TF-IDF + cosine similarity |
| **Export** | openpyxl (styled Excel) |
| **Deployment** | Vercel (frontend) + Render (backend) |

---

## ðŸ“œ License

MIT License â€” Free for personal and commercial use.